{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting s3fs\n",
      "  Downloading s3fs-2023.4.0-py3-none-any.whl (28 kB)\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1\n",
      "  Downloading aiohttp-3.8.4-cp39-cp39-win_amd64.whl (323 kB)\n",
      "     ------------------------------------- 323.6/323.6 kB 20.9 MB/s eta 0:00:00\n",
      "Collecting fsspec==2023.4.0\n",
      "  Downloading fsspec-2023.4.0-py3-none-any.whl (153 kB)\n",
      "     ---------------------------------------- 154.0/154.0 kB ? eta 0:00:00\n",
      "Collecting aiobotocore~=2.5.0\n",
      "  Downloading aiobotocore-2.5.0-py3-none-any.whl (72 kB)\n",
      "     ---------------------------------------- 72.7/72.7 kB ? eta 0:00:00\n",
      "Collecting aioitertools>=0.5.1\n",
      "  Downloading aioitertools-0.11.0-py3-none-any.whl (23 kB)\n",
      "Collecting botocore<1.29.77,>=1.29.76\n",
      "  Downloading botocore-1.29.76-py3-none-any.whl (10.4 MB)\n",
      "     --------------------------------------- 10.4/10.4 MB 36.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: wrapt>=1.10.10 in c:\\users\\lakshmikar reddy\\anaconda3\\lib\\site-packages (from aiobotocore~=2.5.0->s3fs) (1.14.1)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-6.0.4-cp39-cp39-win_amd64.whl (28 kB)\n",
      "Collecting async-timeout<5.0,>=4.0.0a3\n",
      "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.8.2-cp39-cp39-win_amd64.whl (56 kB)\n",
      "     ---------------------------------------- 56.8/56.8 kB ? eta 0:00:00\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.3.3-cp39-cp39-win_amd64.whl (34 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\lakshmikar reddy\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (21.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\users\\lakshmikar reddy\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (2.0.4)\n",
      "Requirement already satisfied: typing_extensions>=4.0 in c:\\users\\lakshmikar reddy\\anaconda3\\lib\\site-packages (from aioitertools>=0.5.1->aiobotocore~=2.5.0->s3fs) (4.3.0)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in c:\\users\\lakshmikar reddy\\anaconda3\\lib\\site-packages (from botocore<1.29.77,>=1.29.76->aiobotocore~=2.5.0->s3fs) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in c:\\users\\lakshmikar reddy\\anaconda3\\lib\\site-packages (from botocore<1.29.77,>=1.29.76->aiobotocore~=2.5.0->s3fs) (2.8.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in c:\\users\\lakshmikar reddy\\anaconda3\\lib\\site-packages (from botocore<1.29.77,>=1.29.76->aiobotocore~=2.5.0->s3fs) (1.26.11)\n",
      "Requirement already satisfied: idna>=2.0 in c:\\users\\lakshmikar reddy\\anaconda3\\lib\\site-packages (from yarl<2.0,>=1.0->aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (3.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\lakshmikar reddy\\anaconda3\\lib\\site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.29.77,>=1.29.76->aiobotocore~=2.5.0->s3fs) (1.16.0)\n",
      "Installing collected packages: multidict, fsspec, frozenlist, async-timeout, aioitertools, yarl, botocore, aiosignal, aiohttp, aiobotocore, s3fs\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2022.7.1\n",
      "    Uninstalling fsspec-2022.7.1:\n",
      "      Successfully uninstalled fsspec-2022.7.1\n",
      "  Attempting uninstall: botocore\n",
      "    Found existing installation: botocore 1.27.28\n",
      "    Uninstalling botocore-1.27.28:\n",
      "      Successfully uninstalled botocore-1.27.28\n",
      "Successfully installed aiobotocore-2.5.0 aiohttp-3.8.4 aioitertools-0.11.0 aiosignal-1.3.1 async-timeout-4.0.2 botocore-1.29.76 frozenlist-1.3.3 fsspec-2023.4.0 multidict-6.0.4 s3fs-2023.4.0 yarl-1.8.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "boto3 1.24.28 requires botocore<1.28.0,>=1.27.28, but you have botocore 1.29.76 which is incompatible.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "####################\n",
    "#Author: brandon chiazza\n",
    "#version: 1.0\n",
    "#purpose: to call a twitter api and return results\n",
    "#documentation: https://developer.twitter.com/en/docs\n",
    "#####################\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import base64\n",
    "!pip install s3fs\n",
    "import s3fs # documentation: https://s3fs.readthedocs.io/en/latest/\n",
    "import time\n",
    "import twitter_keys #this is a custom reference module to a package containing twitter keys\n",
    "\n",
    "%config IPCompleter.greedy=True\n",
    "\n",
    "\n",
    "key_secret = '{}:{}'.format(twitter_keys.client_key, twitter_keys.client_secret).encode('ascii')\n",
    "b64_encoded_key = base64.b64encode(key_secret)\n",
    "b64_encoded_key = b64_encoded_key.decode('ascii')\n",
    "\n",
    "#identify base url and oauth token path\n",
    "base_url = 'https://api.twitter.com/' #base url for authentication\n",
    "auth_url = '{}oauth2/token'.format(base_url)\n",
    "\n",
    "#share header information -- encoding is ascii\n",
    "auth_headers = {\n",
    "    'Authorization': 'Basic {}'.format(b64_encoded_key),\n",
    "    'Content-Type': 'application/x-www-form-urlencoded;charset=UTF-8'\n",
    "}\n",
    "\n",
    "#pass clientcredentials\n",
    "auth_data = {\n",
    "    'grant_type': 'client_credentials'\n",
    "}\n",
    "\n",
    "#send authentication using requests - POST request\n",
    "auth_resp = requests.post(auth_url, headers=auth_headers, data=auth_data)\n",
    "\n",
    "#check response status. 200 = OK\n",
    "auth_resp.status_code\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['token_type', 'access_token'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#Keys in data response are token_type (bearer) and access_token (your access token)\n",
    "print(auth_resp.json().keys())\n",
    "\n",
    "access_token = auth_resp.json()['access_token']\n",
    "\n",
    "\n",
    "search_headers = {\n",
    "    'Authorization': 'Bearer {}'.format(access_token)    \n",
    "}\n",
    "\n",
    "#enter search parameters for coronavirus example. This looks for \"covid-19\" in the 1000 most recent tweets\n",
    "query_params = {\n",
    "    'q': 'covid-19',\n",
    "    'result_type': 'recent',\n",
    "    'count': 100, #update here to get more/less than 1000 returns\n",
    "    'lang': 'en' #filters by english language only\n",
    "}\n",
    "\n",
    "\n",
    "#identify search url path and save \n",
    "search_url = '{}1.1/search/tweets.json'.format(base_url)\n",
    "\n",
    "\n",
    "#run search using get request\n",
    "search_resp = requests.get(search_url, headers=search_headers, params=query_params)\n",
    "\n",
    "#check status code of GET request\n",
    "search_resp.status_code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT @GURU11ji: 1\n",
      "The integrity of Mr. Imran Khan is unquestionable, he is the man who gave the nation charitable cancer hospitals, universit…\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#print text from result to verify  \n",
    "twitter_data = search_resp.json()\n",
    "\n",
    "for x in twitter_data['statuses']:\n",
    "    print(x['text'] + '\\n')\n",
    "    break #prints after one iteration and stops, remove break to see all 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>id</th>\n",
       "      <th>id_str</th>\n",
       "      <th>text</th>\n",
       "      <th>truncated</th>\n",
       "      <th>entities</th>\n",
       "      <th>metadata</th>\n",
       "      <th>source</th>\n",
       "      <th>in_reply_to_status_id</th>\n",
       "      <th>in_reply_to_status_id_str</th>\n",
       "      <th>...</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>favorited</th>\n",
       "      <th>retweeted</th>\n",
       "      <th>lang</th>\n",
       "      <th>possibly_sensitive</th>\n",
       "      <th>quoted_status_id</th>\n",
       "      <th>quoted_status_id_str</th>\n",
       "      <th>quoted_status</th>\n",
       "      <th>extended_entities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sun Apr 16 02:52:58 +0000 2023</td>\n",
       "      <td>1647432870527483910</td>\n",
       "      <td>1647432870527483910</td>\n",
       "      <td>RT @GURU11ji: 1\\nThe integrity of Mr. Imran Kh...</td>\n",
       "      <td>False</td>\n",
       "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
       "      <td>{'iso_language_code': 'en', 'result_type': 're...</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       created_at                   id               id_str  \\\n",
       "0  Sun Apr 16 02:52:58 +0000 2023  1647432870527483910  1647432870527483910   \n",
       "\n",
       "                                                text  truncated  \\\n",
       "0  RT @GURU11ji: 1\\nThe integrity of Mr. Imran Kh...      False   \n",
       "\n",
       "                                            entities  \\\n",
       "0  {'hashtags': [], 'symbols': [], 'user_mentions...   \n",
       "\n",
       "                                            metadata  \\\n",
       "0  {'iso_language_code': 'en', 'result_type': 're...   \n",
       "\n",
       "                                              source  in_reply_to_status_id  \\\n",
       "0  <a href=\"http://twitter.com/download/android\" ...                    NaN   \n",
       "\n",
       "  in_reply_to_status_id_str  ...  retweet_count favorite_count favorited  \\\n",
       "0                      None  ...             44              0     False   \n",
       "\n",
       "  retweeted lang possibly_sensitive quoted_status_id quoted_status_id_str  \\\n",
       "0     False   en                NaN              NaN                  NaN   \n",
       "\n",
       "  quoted_status  extended_entities  \n",
       "0           NaN                NaN  \n",
       "\n",
       "[1 rows x 30 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# move data into data frame \n",
    "df = pd.DataFrame(twitter_data['statuses'])\n",
    "\n",
    "# show one record to verify import \n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Attempt to open non key-like path: s3lab-03Group_720230415234520.csv",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_34132\\1194052295.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mbyte_encoded_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#encodes file as binary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0ms3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ms3fs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mS3FileSystem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0manon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0ms3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilenames3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m     \u001b[0mfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbyte_encoded_df\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#writes byte-encoded file to s3 location\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\fsspec\\spec.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(self, path, mode, block_size, cache_options, compression, **kwargs)\u001b[0m\n\u001b[0;32m   1152\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1153\u001b[0m             \u001b[0mac\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"autocommit\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_intrans\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1154\u001b[1;33m             f = self._open(\n\u001b[0m\u001b[0;32m   1155\u001b[0m                 \u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1156\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\s3fs\\core.py\u001b[0m in \u001b[0;36m_open\u001b[1;34m(self, path, mode, block_size, acl, version_id, fill_cache, cache_type, autocommit, requester_pays, cache_options, **kwargs)\u001b[0m\n\u001b[0;32m    657\u001b[0m             \u001b[0mcache_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdefault_cache_type\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    658\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 659\u001b[1;33m         return S3File(\n\u001b[0m\u001b[0;32m    660\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    661\u001b[0m             \u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\s3fs\\core.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, s3, path, mode, block_size, acl, version_id, fill_cache, s3_additional_kwargs, autocommit, cache_type, requester_pays, cache_options)\u001b[0m\n\u001b[0;32m   2008\u001b[0m         \u001b[0mbucket\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath_version_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ms3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2009\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2010\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Attempt to open non key-like path: %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2011\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbucket\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbucket\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2012\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Attempt to open non key-like path: s3lab-03Group_720230415234520.csv"
     ]
    }
   ],
   "source": [
    "# we can use pandas to put data directly into an s3 bucket\n",
    "#prepare csv file name   \n",
    "filename = 's3lab-03'#specify location of s3:/{my-bucket}/\n",
    "groupname= 'Group_7' #name of your group\n",
    "datetime = time.strftime(\"%Y%m%d%H%M%S\") #timestamp\n",
    "filenames3 = \"%s%s%s.csv\"%(filename,groupname,datetime) #name of the filepath and csv file\n",
    "\n",
    "\n",
    "\n",
    "#encoding must be adjusted to accommodate abnormal characters. Use s3fs to write to S3 bucket\n",
    "byte_encoded_df = df.to_csv(None).encode() #encodes file as binary\n",
    "s3 = s3fs.S3FileSystem(anon=False)\n",
    "with s3.open(filenames3, 'wb') as file:\n",
    "    file.write(byte_encoded_df) #writes byte-encoded file to s3 location\n",
    "\n",
    "#print success message\n",
    "print(\"Successfully uploaded file to location:\"+str(filenames3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
